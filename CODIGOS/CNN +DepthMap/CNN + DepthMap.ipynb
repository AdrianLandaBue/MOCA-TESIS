{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376614e-0855-4de2-8708-e107a2723fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16fc8a5-cc51-49a2-9a86-2d4cc472ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Se redimensionarán las imágenes para trabajarlas a 150x150 pixeles\n",
    "IMG_WIDTH, IMG_HEIGHT = 150, 150\n",
    "\n",
    "# Se definen las rutas de las carpetas de entrenamiento y validación\n",
    "\n",
    "\n",
    "train_dir = \"V:/ProyectoMOCA/ProyectoDL_depth/train\"\n",
    "validation_dir = \"V:/ProyectoMOCA/ProyectoDL_depth/validation\"\n",
    "# Crear un generador de imágenes para el preprocesamiento de los datos\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,             # Normalizar imágenes\n",
    "    shear_range=0.2,            # Transformación aleatoria\n",
    "    zoom_range=0.2,             # Zoom aleatorio\n",
    "    horizontal_flip=True)       # Volteo horizontal de las imágenes\n",
    "\n",
    "# Imágenes de entrenamiento\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')    # Modo categórico para múltiples clases\n",
    "\n",
    "# Imágenes para la validación (solo rescalado)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3206b6f5-fe93-425e-bf9d-f42043a077e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Para hacer uso de la GPU usar \"Python (tf_venv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90447142-e3d8-4314-9853-16b83754093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Definimos la arquitectura de la CNN\n",
    "model = models.Sequential()\n",
    "\n",
    "# Primera capa convolucional + MaxPooling\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Segunda capa convolucional + MaxPooling\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Tercera capa convolucional + MaxPooling\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Cuarta capa convolucional + MaxPooling\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Aplanar las capas\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Añadir una capa densa completamente conectada\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "\n",
    "# Capa de salida con softmax para clasificación \n",
    "model.add(layers.Dense(10, activation='softmax'))   # 10 clases (c0 - c9)\n",
    "\n",
    "# Compilación del modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58669c4c-12e1-4a28-b957-504ff7d13b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5489aa6-48c9-441b-96fc-ce52200baa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================\n",
    "#  GRÁFICA DE ACCURACY\n",
    "# ============================\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['accuracy'], label='Accuracy entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Accuracy validación')\n",
    "plt.title('Accuracy durante el entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ============================\n",
    "#  GRÁFICA DE LOSS\n",
    "# ============================\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['loss'], label='Loss entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Loss validación')\n",
    "plt.title('Pérdida durante el entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c269e4-834b-478b-aac0-b7060c993283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de validación\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Accuracy en validación: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae06b4c1-de51-4318-b2dd-8a2cae5ae3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# 1. Preparar el generador de datos para el conjunto de prueba\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Solo rescalado, sin aumentación\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    \"V:/ProyectoMOCA/ProyectoDL_depth/test\",         # Ruta al conjunto de prueba\n",
    "    target_size=(150, 150),                        # Tamaño de las imágenes que espera el modelo\n",
    "    batch_size=32,                                 # Tamaño de lote\n",
    "    class_mode='categorical',                      # Cambiar a 'categorical' para múltiples clases\n",
    "    shuffle=False                                  # No barajar para mantener el orden\n",
    ")\n",
    "\n",
    "# 2. Evaluar el modelo en el conjunto de prueba\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Pérdida en prueba: {loss:.4f}\")\n",
    "print(f\"Precisión en prueba: {accuracy*100:.2f}%\")\n",
    "\n",
    "# 3. Seleccionar una imagen aleatoria\n",
    "# Directorio de prueba\n",
    "test_dir = \"V:/ProyectoMOCA/ProyectoDL_depth/test\"\n",
    "\n",
    "# Seleccionar una clase al azar\n",
    "class_folders = os.listdir(test_dir)\n",
    "random_class = random.choice(class_folders)  # Elegir una clase aleatoria\n",
    "\n",
    "# Seleccionar una imagen al azar de la clase elegida\n",
    "class_path = os.path.join(test_dir, random_class)\n",
    "image_files = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
    "random_image = random.choice(image_files)\n",
    "\n",
    "# Ruta completa de la imagen\n",
    "img_path = os.path.join(class_path, random_image)\n",
    "print(f\"Imagen seleccionada: {img_path}\")\n",
    "\n",
    "# Cargar la imagen y procesarla\n",
    "img = load_img(img_path, target_size=(150, 150))  # Redimensionar\n",
    "img_array = img_to_array(img) / 255.0             # Convertir a tensor y normalizar\n",
    "img_array = np.expand_dims(img_array, axis=0)     # Agregar dimensión de lote\n",
    "\n",
    "# Predecir la clase de la imagen\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "# Interpretar la predicción\n",
    "class_indices = test_generator.class_indices       # Diccionario de clases\n",
    "class_labels = list(class_indices.keys())          # Etiquetas de clases\n",
    "\n",
    "predicted_class = np.argmax(prediction[0])         # Clase con mayor probabilidad\n",
    "predicted_label = class_labels[predicted_class]    # Etiqueta de la clase predicha\n",
    "\n",
    "print(f\"Predicción: Clase {predicted_class} ({predicted_label})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698bf1a-41fe-408d-bba1-42aafbdd2991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np, os, random, math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_dir = r\"V:/ProyectoMOCA/ProyectoDL/test\"\n",
    "img_size = (150, 150)\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Cargar imágenes SIN etiquetas desde la raíz\n",
    "test_gen_no_labels = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,        # <— sin etiquetas\n",
    "    shuffle=False,\n",
    "    classes=['.']           # <— leer desde la raíz del folder\n",
    ")\n",
    "\n",
    "print(\"Imágenes encontradas:\", test_gen_no_labels.samples)  # Verifica que > 0\n",
    "\n",
    "# Predicciones de TODO el set (sin métricas, solo y_pred_proba)\n",
    "y_pred_proba = model.predict(test_gen_no_labels, verbose=1)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Si quieres ver N imágenes aleatorias con su predicción:\n",
    "N = 5\n",
    "all_files = [f for f in os.listdir(test_dir)\n",
    "             if os.path.isfile(os.path.join(test_dir, f))\n",
    "             and os.path.splitext(f)[1].lower() in {'.jpg','.jpeg','.png','.bmp','.gif'}]\n",
    "\n",
    "for _ in range(min(N, len(all_files))):\n",
    "    fname = random.choice(all_files)\n",
    "    path = os.path.join(test_dir, fname)\n",
    "    img = load_img(path, target_size=img_size)\n",
    "    arr = img_to_array(img)/255.0\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    probs = model.predict(arr, verbose=0)[0]\n",
    "    pred_idx = int(np.argmax(probs))\n",
    "    pred_prob = float(probs[pred_idx])\n",
    "\n",
    "    # Si tienes el mapeo de clases del entrenamiento:\n",
    "    # class_indices = train_generator.class_indices\n",
    "    # idx_to_class = {v:k for k,v in class_indices.items()}\n",
    "    # pred_label = idx_to_class[pred_idx]\n",
    "    pred_label = f\"clase_{pred_idx}\"\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Pred: {pred_label} ({pred_prob:.1%})\\n{fname}\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_venv)",
   "language": "python",
   "name": "tf_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
